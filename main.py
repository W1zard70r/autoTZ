import os
from typing import List

from models.inputs import DataSource, DataEnum
from models.graph import UnifiedGraph
from models.document import FullTZDocument
from services.extractor import DataExtractorService
from services.merger import GraphMergerService
from services.generator import TZGeneratorService

def load_graphml(filepath: str) -> DataSource:
    with open(filepath, 'r', encoding='utf-8') as f:
        return DataSource(
            source_type=DataEnum.GRAPHML,
            content=f.read(),
            file_name=os.path.basename(filepath)
        )

def main():
    print("==========================================")
    print("üöÄ –ì–ï–ù–ï–†–ê–¢–û–† –¢–ó (GRAPHML EDITION)")
    print("==========================================\n")

    extractor = DataExtractorService()
    merger = GraphMergerService()
    generator = TZGeneratorService()

    # –ë–µ—Ä–µ–º 3 –≥—Ä–∞—Ñ–∞: —Ç–≤–æ–π backend –∏ 2 –Ω–æ–≤—ã—Ö –æ—Ç –¥—Ä—É–≥–∞
    files = [
        "data/telegram_backend_team.graphml",
        "data/frontend_app.graphml",
        "data/deploy_infra.graphml"
    ]
    
    inputs = []
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–æ–≤:")
    for f in files:
        if os.path.exists(f):
            inputs.append(load_graphml(f))
            print(f"  - {f} (ok)")
        else:
            print(f"  - {f} (–ù–ï –ù–ê–ô–î–ï–ù)")

    # 1. PARSING (–ë–µ–∑ LLM)
    print("\n--- –≠–¢–ê–ü 1: –ü–ê–†–°–ò–ù–ì –ì–†–ê–§–û–í ---")
    chunks = []
    for src in inputs:
        chunk = extractor.extract(src)
        chunks.append(chunk)
        print(f"  ‚úÖ {src.file_name}: —É–∑–ª–æ–≤={len(chunk.nodes)}, —Å–≤—è–∑–µ–π={len(chunk.edges)}")

    # 2. MERGING (–° LLM)
    print("\n--- –≠–¢–ê–ü 2: –°–õ–ò–Ø–ù–ò–ï (LLM) ---")
    unified_graph = merger.merge(chunks)
    print(f"  ‚úÖ –ì—Ä–∞—Ñ –æ–±—ä–µ–¥–∏–Ω–µ–Ω. –£–∑–ª–æ–≤: {len(unified_graph.nodes)}")
    
    # 3. GENERATION (–° LLM)
    print("\n--- –≠–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ó ---")
    try:
        doc = generator.generate(unified_graph, template={})
        with open("FINAL_TZ.md", "w", encoding="utf-8") as f:
            f.write(f"# {doc.project_name}\n\n")
            for sec in doc.sections:
                f.write(f"## {sec.title}\n{sec.content_markdown}\n\n")
        print(f"\nüéâ –ì–û–¢–û–í–û! –§–∞–π–ª: FINAL_TZ.md")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()