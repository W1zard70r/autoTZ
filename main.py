import os
import asyncio
import logging
from dotenv import load_dotenv

from schemas.document import DataSource
from schemas.enums import DataEnum
from layer1_miner.extractor import MinerProcessor
from layer2_merger.merger import SmartGraphMerger
from layer3_compiler.generator import TZGenerator
from utils.test_data_gen import get_backend_chat_dataset, get_frontend_chat_dataset

load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)


async def main():
    print("==================================================")
    print("üöÄ –ì–ï–ù–ï–†–ê–¢–û–† –¢–ó (3-LAYER GRAPH PIPELINE)")
    print("==================================================\n")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–µ–≤
    miner = MinerProcessor()
    merger = SmartGraphMerger()
    compiler = TZGenerator()

    # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–º–∏—Ç–∞—Ü–∏—è —á–∞—Ç–∞)
    sources = [
        DataSource(
            source_type=DataEnum.CHAT,
            content=get_backend_chat_dataset(),
            file_name="chat_backend_team"
        ),
        DataSource(
            source_type=DataEnum.CHAT,
            content=get_frontend_chat_dataset(),
            file_name="chat_frontend_team"
        )
    ]

    # ---------------------------------------------------------
    # –≠–¢–ê–ü 1: MINER (–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥–≥—Ä–∞—Ñ–æ–≤ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)
    # ---------------------------------------------------------
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 1: –ú–∞–π–Ω–∏–Ω–≥ –∑–Ω–∞–Ω–∏–π")

    all_extracted_subgraphs = []

    for source in sources:
        logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source.file_name}")
        # –ú–∞–π–Ω–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏
        subgraphs = await miner.process_source(source)
        all_extracted_subgraphs.extend(subgraphs)
        logger.info(f"   -> –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(subgraphs)} —á–∞–Ω–∫–æ–≤ –∏–∑ {source.file_name}")

    # ---------------------------------------------------------
    # –≠–¢–ê–ü 2: MERGER (–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ –°–ª–∏—è–Ω–∏–µ)
    # ---------------------------------------------------------
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 2")
    unified_graph = await merger.smart_merge(all_extracted_subgraphs)
    logger.info(f"‚úÖ –ì—Ä–∞—Ñ –æ–±—ä–µ–¥–∏–Ω–µ–Ω. –ò—Ç–æ–≥–æ–≤—ã—Ö —É–∑–ª–æ–≤: {len(unified_graph.nodes)}")
    print("-" * 50)

    # ---------------------------------------------------------
    # –≠–¢–ê–ü 3: COMPILER (–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown)
    # ---------------------------------------------------------
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 3")
    doc = await compiler.generate_tz(unified_graph)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "FINAL_TZ.md")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(f"# {doc.project_name}\n")
        f.write(f"**–í–µ—Ä—Å–∏—è:** {doc.version}\n\n")
        f.write("---\n\n")
        for sec in doc.sections:
            f.write(f"## {sec.title}\n\n")
            f.write(f"{sec.content_markdown}\n\n")
            f.write("---\n\n")

    logger.info(f"üéâ –ì–û–¢–û–í–û! –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    print("==================================================")


if __name__ == "__main__":
    asyncio.run(main())