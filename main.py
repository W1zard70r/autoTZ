import os
import asyncio
import logging
from dotenv import load_dotenv

from schemas.document import DataSource
from schemas.enums import DataEnum
from layer1_miner.extractor import MinerProcessor
from layer2_merger.merger import SmartGraphMerger
from layer3_compiler.generator import TZGenerator
from utils.test_data_gen import get_backend_chat_dataset, get_frontend_chat_dataset
from utils.state_logger import init_logs_dir

load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–ø–∫—É –ª–æ–≥–æ–≤
init_logs_dir()

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –¥–≤–æ–π–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤ –∫–æ–Ω—Å–æ–ª—å –∏ –≤ —Ñ–∞–π–ª app.log)
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s', 
    datefmt='%H:%M:%S',
    handlers=[
        logging.FileHandler("logs/app.log", encoding="utf-8", mode="w"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


async def main():
    print("==================================================")
    print("üöÄ –ì–ï–ù–ï–†–ê–¢–û–† –¢–ó (3-LAYER GRAPH PIPELINE –° –õ–û–ì–ê–ú–ò)")
    print("==================================================\n")

    miner = MinerProcessor()
    merger = SmartGraphMerger()
    compiler = TZGenerator()

    sources = [
        DataSource(
            source_type=DataEnum.CHAT,
            content=get_backend_chat_dataset(),
            file_name="chat_backend_team"
        ),
        DataSource(
            source_type=DataEnum.CHAT,
            content=get_frontend_chat_dataset(),
            file_name="chat_frontend_team"
        )
    ]

    # --- –≠–¢–ê–ü 1: MINER ---
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 1: –ú–∞–π–Ω–∏–Ω–≥ –∑–Ω–∞–Ω–∏–π")
    all_extracted_subgraphs = []

    for source in sources:
        logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source.file_name}")
        subgraphs = await miner.process_source(source)
        all_extracted_subgraphs.extend(subgraphs)
        logger.info(f"   -> –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(subgraphs)} —á–∞–Ω–∫–æ–≤ –∏–∑ {source.file_name}")

    print("-" * 50)

    # --- –≠–¢–ê–ü 2: MERGER ---
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 2: –°–ª–∏—è–Ω–∏–µ")
    unified_graph = await merger.smart_merge(all_extracted_subgraphs)
    logger.info(f"‚úÖ –ì—Ä–∞—Ñ –æ–±—ä–µ–¥–∏–Ω–µ–Ω. –ò—Ç–æ–≥–æ–≤—ã—Ö —É–∑–ª–æ–≤: {len(unified_graph.nodes)}")
    
    print("-" * 50)

    # --- –≠–¢–ê–ü 3: COMPILER ---
    logger.info(">>> –°–¢–ê–†–¢ –≠–¢–ê–ü–ê 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è")
    doc = await compiler.generate_tz(unified_graph)

    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "FINAL_TZ.md")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(f"# {doc.project_name}\n")
        f.write(f"**–í–µ—Ä—Å–∏—è:** {doc.version}\n\n")
        f.write("---\n\n")
        for sec in doc.sections:
            f.write(f"## {sec.title}\n\n")
            f.write(f"{sec.content_markdown}\n\n")
            f.write("---\n\n")

    logger.info(f"üéâ –ì–û–¢–û–í–û! –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    print("==================================================")


if __name__ == "__main__":
    asyncio.run(main())