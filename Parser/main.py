import os
import json
import asyncio
from dotenv import load_dotenv
from models import DataSource, DataEnum
from processor import Layer1Processor
from test_data_gen import get_huge_chat_dataset

load_dotenv()
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

async def main():
    # 1. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–ò–º–∏—Ç–∞—Ü–∏—è —Å–ª–æ–∂–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞)
    chat_data = {
        "messages": get_huge_chat_dataset()
    }

    source = DataSource(
        source_type=DataEnum.CHAT,
        content=chat_data["messages"],
        file_name="telegram_backend_team"
    )

    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    processor = Layer1Processor()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    graph_manager = await processor.process_source(source)

    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    os.makedirs("output", exist_ok=True)

    # –≠–∫—Å–ø–æ—Ä—Ç –≤ GraphML (–î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ Gephi / Neo4j)
    graphml_path = os.path.join("output", f"{source.file_name}.graphml")
    graph_manager.export_to_graphml(graphml_path)
    print(f"‚úÖ –ì—Ä–∞—Ñ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ GraphML: {graphml_path}")

    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥—Ä–∞—Ñ–∞:")
    print(f"–£–∑–ª–æ–≤: {graph_manager.graph.number_of_nodes()}")
    print(f"–°–≤—è–∑–µ–π: {graph_manager.graph.number_of_edges()}")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ event loop
    asyncio.run(main())