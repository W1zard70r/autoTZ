import logging
import networkx as nx
from typing import List
from pydantic import BaseModel, Field
from schemas.graph import ExtractedKnowledge, UnifiedGraph, GraphNode, GraphEdge, Conflict
from schemas.enums import TZSectionEnum, NodeLabel
from utils.llm_client import acall_llm_json

logger = logging.getLogger(__name__)


class MergeAction(BaseModel):
    is_duplicate: bool = Field(description="–≠—Ç–æ –æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ —Å—É—â–Ω–æ—Å—Ç—å?")
    ids_to_merge: List[str] = Field(description="–°–ø–∏—Å–æ–∫ ID, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Å–ª–∏—Ç—å –≤ –æ–¥–∏–Ω")
    unified_id: str = Field(description="–ù–æ–≤—ã–π ID –¥–ª—è —Å–ª–∏—Ç–æ–≥–æ —É–∑–ª–∞")
    unified_name: str = Field(description="–û–±—â–µ–µ –∏–º—è")
    unified_desc: str = Field(description="–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")


class MergeBatchResult(BaseModel):
    actions: List[MergeAction] = Field(default_factory=list)


class SectionAssignment(BaseModel):
    node_id: str
    target_section: TZSectionEnum


class SectionBatchResult(BaseModel):
    assignments: List[SectionAssignment]


class SmartGraphMerger:
    def __init__(self):
        self.G = nx.DiGraph()
        self.conflicts: List[Conflict] = []

    async def smart_merge(self, subgraphs: List[ExtractedKnowledge]) -> UnifiedGraph:
        logger.info("üîó –°–õ–û–ô 2: –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–¥–≥—Ä–∞—Ñ–æ–≤ –≤ –µ–¥–∏–Ω—ã–π –≥—Ä–∞—Ñ NetworkX")

        for sg in subgraphs:
            for node in sg.nodes:
                if not self.G.has_node(node.id):
                    self.G.add_node(node.id, **node.model_dump())
            for edge in sg.edges:
                # !!! –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ò—Å–∫–ª—é—á–∞–µ–º source –∏ target –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –≥—Ä–∞—Ñ,
                # —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ç–æ–ø–æ–ª–æ–≥–∏–µ–π –≥—Ä–∞—Ñ–∞ (u -> v)
                edge_data = edge.model_dump(exclude={'source', 'target'})
                self.G.add_edge(edge.source, edge.target, **edge_data)

        logger.info(f"  -> –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {self.G.number_of_nodes()} —É–∑–ª–æ–≤, {self.G.number_of_edges()} —Å–≤—è–∑–µ–π.")

        # ... (–∫–æ–¥ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å–µ–∫—Ü–∏—è–º –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...

        nodes_by_label = {}
        for nid, data in self.G.nodes(data=True):
            label = data.get("label")
            if label not in nodes_by_label:
                nodes_by_label[label] = []
            nodes_by_label[label].append({"id": nid, "name": data.get("name"), "desc": data.get("description")})

        for label, nodes in nodes_by_label.items():
            if len(nodes) < 2: continue

            # (–õ–æ–≥–∏–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–ø—É—â–µ–Ω–∞ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, –æ–Ω–∞ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è)
            logger.info(f"  -> –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –≥—Ä—É–ø–ø—ã '{label}' ({len(nodes)} —É–∑–ª–æ–≤)...")
            batch_size = 15
            for i in range(0, len(nodes), batch_size):
                batch = nodes[i:i + batch_size]
                prompt = """–¢—ã –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä. –ù–∞–π–¥–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ä–µ–¥–∏ —ç—Ç–∏—Ö —É–∑–ª–æ–≤ (—Å–∏–Ω–æ–Ω–∏–º—ã, –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –ø–æ–Ω—è—Ç–∏–µ).
                –ï—Å–ª–∏ –Ω–∞—Ö–æ–¥–∏—à—å –¥—É–±–ª–∏–∫–∞—Ç—ã, –≤–µ—Ä–Ω–∏ MergeAction —Å is_duplicate=true.
                –ï—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ actions."""
                data_str = "\n".join([f"ID: {n['id']} | –ò–º—è: {n['name']} | –û–ø–∏—Å–∞–Ω–∏–µ: {n['desc']}" for n in batch])
                try:
                    result = await acall_llm_json(schema=MergeBatchResult, prompt=prompt, data=data_str)
                    for action in result.actions:
                        if action.is_duplicate and len(action.ids_to_merge) > 1:
                            self._merge_nodes_in_graph(action)
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {e}")

        await self._assign_sections()

        final_nodes = []
        for nid, data in self.G.nodes(data=True):
            node_data = data.copy()
            if "id" not in node_data:
                node_data["id"] = nid

            if "target_section" in node_data and isinstance(node_data["target_section"], str):
                try:
                    node_data["target_section"] = TZSectionEnum(node_data["target_section"])
                except ValueError:
                    node_data["target_section"] = TZSectionEnum.UNKNOWN

            final_nodes.append(GraphNode(**node_data))

        # !!! –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–±–µ—Ä
        final_edges = []
        for u, v, data in self.G.edges(data=True):
            # –£–¥–∞–ª—è–µ–º source/target –∏–∑ data, –µ—Å–ª–∏ –æ–Ω–∏ —Ç–∞–º —Å–ª—É—á–∞–π–Ω–æ –æ–∫–∞–∑–∞–ª–∏—Å—å,
            # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            clean_data = {k: val for k, val in data.items() if k not in {'source', 'target'}}
            final_edges.append(GraphEdge(source=u, target=v, **clean_data))

        return UnifiedGraph(nodes=final_nodes, edges=final_edges, conflicts=self.conflicts)

    def _merge_nodes_in_graph(self, action: MergeAction):
        # ... (–æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –º–µ—Ç–æ–¥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        valid_ids = [nid for nid in action.ids_to_merge if self.G.has_node(nid)]
        if not valid_ids: return

        primary_id = action.unified_id
        if not self.G.has_node(primary_id):
            base_data = self.G.nodes[valid_ids[0]].copy()
            base_data.update({
                "id": primary_id,
                "name": action.unified_name,
                "description": action.unified_desc
            })
            self.G.add_node(primary_id, **base_data)

        for old_id in valid_ids:
            if old_id == primary_id: continue

            for u, v, data in list(self.G.edges(old_id, data=True)):
                if u == old_id: self.G.add_edge(primary_id, v, **data)

            for u, v, data in list(self.G.in_edges(old_id, data=True)):
                if v == old_id: self.G.add_edge(u, primary_id, **data)

            self.G.remove_node(old_id)

    async def _assign_sections(self):
        # ... (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        logger.info("  -> –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ –ø–æ —Å–µ–∫—Ü–∏—è–º –¢–ó...")
        nodes_to_assign = [{"id": n, "name": d.get("name"), "label": d.get("label")}
                           for n, d in self.G.nodes(data=True) if d.get("label") != NodeLabel.PERSON]

        if not nodes_to_assign: return

        prompt = """–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏ –∫–∞–∂–¥—ã–π —É–∑–µ–ª –≤ –æ–¥–Ω—É –∏–∑ —Å–µ–∫—Ü–∏–π –¢–ó:
        - GENERAL (–æ–±—â–∞—è –∏–Ω—Ñ–∞, –∑–∞–¥–∞—á–∏)
        - STACK (–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –ë–î, –ª–∏–±—ã)
        - FUNCTIONAL (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —Ñ–∏—á–∏)
        - INTERFACE (–≤—Å—ë –ø—Ä–æ UI/UX)"""

        batch_size = 20
        for i in range(0, len(nodes_to_assign), batch_size):
            batch = nodes_to_assign[i:i + batch_size]
            data_str = "\n".join([f"ID:{n['id']} | {n['label']} | {n['name']}" for n in batch])
            try:
                result = await acall_llm_json(schema=SectionBatchResult, prompt=prompt, data=data_str)
                for assignment in result.assignments:
                    if self.G.has_node(assignment.node_id):
                        self.G.nodes[assignment.node_id]["target_section"] = assignment.target_section
            except Exception:
                pass